# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---

### Решение

#### Задача 1. Обеспечить разработку

1. Организовать инфраструктуру для разработки и эксплуатации микросервисов в ***Yandex Cloud***.
YC - крупный отечественный облачный провайдер, имеющий интеграцию с другими сервисами Яндекса.

2. Использовать в качестве системы контроля версий ***GitLab***, развернутый в Yandex Cloud Managed Service for GitLab или self-hosted на Yandex Compute Cloud.
Gitlab - полноценная платформа для хранения кода, CI/CD, управления репозиториями. Имеет поддержку отдельных репозиториев под каждый микросервис, встроенный CI/CD, позволяющий запускать сборки по push/merge в Git или вручную с параметрами. Также позволяет создать шаблоны сборок и поддерживает параллельные сборки (используя несколько runners) и параллельные тесты.

3. CI/CD-система ***GitLab CI/CD*** + ***GitLab Runners***

* Запуск сборки по событию (push, merge request) или вручную через кнопку. 
* Настройки для каждой сборки — через variables в .gitlab-ci.yml. 
* Собственные Docker-образы для сборки — можно указывать в image в .gitlab-ci.yml. 
* Кастомные шаги сборки — написание скриптов в script. 
* Развертывание runners на собственных серверах. 
* Использование variables и rules позволяет запускать разные шаги сборки в зависимости от переменных (ветка, тег, ручной запуск). 
* Использование include и шаблонов позволяет вынести разные конфигурации в отдельные файлы и подключать их динамически 

4. Хранение секретов
***HashiCorp Vault***, развернутый в Yandex Managed Service for Kubernetes (для сложных проектов с высокими требованиями к безопасности)

* Безопасное хранение паролей, ключей, сертификатов. 
* Интеграция с GitLab CI через Vault Secrets Engine. 
* Динамические секреты (временные доступы). 

Можно также использовать ***Yandex Lockbox*** для простых проектов или, если не планируется "переезжать в другое облако".

5. ***Yandex Container Registry*** для хранения Docker-образов. Интегрируется с GitLab CI.

5. Оркестрация и деплой
Yandex Managed Service for ***Kubernetes***

* Каждый микросервис упаковывается в отдельный контейнер и развертывается в Kubernetes как Pod + Deployment. 
* Встроенная сеть упрощает коммуникацию между сервисами. 
* Автоматически увеличивает/уменьшает количество реплик приложения в зависимости от нагрузки. 
* GitLab CI и Argo CD работают с Kubernetes нативно. 


#### Задача 2. Логи

***ELK-стек с использованием Filebeat***

1. Сбор логов с использованием Filebeat 

* Filebeat устанавливаются на все хосты, с которых собираются логи 
* Минимальное потребление ресурсов (~10MB RAM) 
* Встроенные модули для парсинга (Nginx, Docker, Kafka и др.) 
* Сбор логов из stdout 

2. Гарантия доставки 

Filebeat ждёт подтверждения от Logstash. Logstash, как и Filebeat сохраняет логи в оперативной памяти и на диск (Filebeat: с диска данные удаляются только после подтверждения от Logstash; Logstash: данные удаляются после успешной отправки в Elasticsearch)

3. Обработка логов

В конфигурационом файле Logstash настраивается:

* Парсинг JSON-логов 
* Добавление тегов для классификации ошибок 
* Фильтрация чувствительных данных 

4. Визуализация в Kibana

* Интерактивные дашборды и графики для анализа трендов 
* Сохранение поисковых запросов с возможностью делиться ссылками 

**В итоге:**
Filebeat сам находит логи в контейнерах (Kubernetes/Docker) — не нужно править код приложений.
Хранит копию логов на диске, пока не получит подтверждение доставки. Если связь оборвется — отправит заново после восстановления. 
Elasticsearch Дублирует данные на нескольких репликах. 
Elasticsearch осуществляет полнотекстовый поиск. 
Kibana имеет удобный визуальный интерфейс с графиками. Можно сохранить поиск и дать ссылку коллегам.  


#### Задача 3. Мониторинг

***Prometheus + Grafana***

1. Сбор метрик со всех хостов

* Автоматическое обнаружение хостов через service discovery (Kubernetes). 
* Универсальные экспортеры: node_exporter для физических серверов и виртуальных машин и kube-state-metrics для Kubernetes-кластеров. 

2. Сбор метрик состояния ресурсов хостов (CPU, RAM, HDD, Network)

node_exporter собирает метрики:

* CPU: node_cpu_seconds_total. 
* RAM: node_memory_MemTotal_bytes, node_memory_MemFree_bytes. 
* Диск: node_disk_io_time_seconds_total, node_filesystem_avail_bytes. 
* Сеть: node_network_receive_bytes_total. 

Можно использовать PromQL для написания запросов и получения нужной информации.

3. Сбор метрик потребляемых ресурсов для каждого сервиса

Для контейнеров: cAdvisor (встроен в Kubelet) собирает метрики
Для процессов: библиотеки Prometheus (Python, Go, Java) добавляют метрики

4. Сбор специфичных метрик сервисов

Для каждого сервиса могут потребоваться свои экспортеры. Например, для баз данных можно использовать MySQL Exporter или PostgreSQL Exporter, для веб-серверов — NGINX Exporter и т.д.

5. Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию

В Grafana используется PromQL для сложных запросов.
Grafana поддерживает различные функции агрегации, такие как sum, avg, max, min, которые можно использовать для агрегации данных по времени или меткам.

6. Пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы

Grafana предоставляет гибкий пользовательский интерфейс, который позволяет настраивать различные панели для отслеживания состояния системы. В ней можно создать:

* Дашборды 
* Панели 

Типы панелей: графики, таблицы, гистограммы, тепловые карты и т.д.

В Grafana настраиваются оси и легенды, цветовые схемы, пороговые значения и др.